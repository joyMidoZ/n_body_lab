<?xml version='1.0' encoding='UTF-8'?>

<bag xmlns:boolean="http://www.w3.org/2001/XMLSchema#boolean" xmlns:float="http://www.w3.org/2001/XMLSchema#float" xmlns:int="http://www.w3.org/2001/XMLSchema#int" xmlns:unsignedInt="http://www.w3.org/2001/XMLSchema#unsignedInt" xmlns:unsignedLong="http://www.w3.org/2001/XMLSchema#unsignedLong" int:version="16">
 <issues>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>13</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/current/pragmas.html&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/advisor-vectorization-resources.html&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>std::array&lt;struct body,10000&gt;::operator[]</item>
       <item>std::array&lt;struct body,10000&gt;::size</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>69</unsignedInt:flags>
   <id>issue_check_access_patterns</id>
   <int:severity>2</int:severity>
   <text>Inefficient memory access patterns may result in significant vector code execution slowdown or block automatic vectorization by the compiler. Improve performance by investigating. </text>
   <title>Possible inefficient memory access patterns present </title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_check_access_patterns_run_map_c</id>
     <text>There is no confirmation inefficient memory access patterns are present. To confirm: Run a &lt;a href=&quot;../help/index.htm#GUID-B98AD81B-4946-4E86-B452-9A1810F4517C.htm&quot;&gt;Memory Access Patterns analysis&lt;/a&gt;. </text>
     <title>Confirm inefficient memory access patterns </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:no_map_disclaimer>true</boolean:no_map_disclaimer>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_fma</id>
   <int:severity>1</int:severity>
   <text>Your current hardware supports the AVX2 instruction set architecture (ISA), which enables the use of fused multiply-add (FMA) instructions. Improve performance by utilizing FMA instructions. </text>
   <title>Potential underutilization of FMA instructions </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_fma_target_avx2_isa_c</id>
     <text>Although static analysis presumes the loop may benefit from FMA instructions available with the AVX2 ISA, no AVX2-specific code executed for this loop. To fix: Use the &lt;div class=&quot;inplace_sample&quot;&gt;xCORE-AVX2&lt;/div&gt; compiler option to generate AVX2-specific code, or the &lt;div class=&quot;inplace_sample&quot;&gt;axCORE-AVX2&lt;/div&gt; compiler option to enable multiple, feature-specific, auto-dispatch code generation, including AVX2. &lt;table&gt; &lt;tr&gt; &lt;th&gt; Windows* OS &lt;/th&gt; &lt;th&gt; Linux* OS &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;/QxCORE-AVX2 or /QaxCORE-AVX2&lt;/td&gt; &lt;td&gt;-xCORE-AVX2 or -axCORE-AVX2&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More: &lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-2D881A91-C5D7-4DDD-84B1-FB9D0D597F4D.htm&quot;&gt;ax, Qax&lt;/a&gt;; &lt;a href=&quot;C++/17/index.htm#GUID-09734487-1819-4C1E-B314-2497F2B64C45.htm&quot;&gt;x, Qx&lt;/a&gt;
&lt;li&gt;&lt;em&gt;Code Generation Options&lt;/em&gt; in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/current/overview.html&quot;&gt;Intel&amp;reg; C++ Compiler 16.0 User and Reference Guide&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/architecture-and-technology/avx-512-solution-brief.html&quot;&gt;Compiling for the Intel&amp;reg; Xeon Phi&amp;trade; processor x200 and the Intel&amp;reg; AVX-512 ISA&lt;/a&gt; and &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/advisor-vectorization-resources.html&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Target the AVX2 ISA </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_simd_c</id>
     <text>Force vectorization of the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; using SIMD instructions and/or generate vector variants of the function(s) using a &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;br/&gt;&lt;b&gt;Example:&lt;/b&gt; &lt;br/&gt; Original code: &lt;div class=&quot;sample&quot;&gt; struct A {&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;virtual double foo(double x) { return x+1; }&lt;br/&gt; };&lt;br/&gt; &lt;br/&gt; struct B : public A {&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;double foo(double x) override { return x-1; }&lt;br/&gt; };&lt;br/&gt; &lt;br/&gt; . . .&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;A* obj = new B();&lt;br/&gt; &lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;double sum = 0.0;&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;#pragma omp simd reduction(+:sum)&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;for (int k = 0; k &lt; N; ++k) {&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;// indirect call to virtual method&lt;/strong&gt;&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;sum += obj-&gt;foo(a[k]);&lt;/strong&gt;&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;}&lt;br/&gt; . . . &lt;/div&gt; Revised code: &lt;div class=&quot;sample&quot;&gt; struct A {&lt;br/&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;#pragma omp declare simd&lt;br/&gt;&lt;/strong&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;virtual double foo(double x) { return x+1; }&lt;br/&gt; };&lt;br/&gt; . . . &lt;/div&gt;
&lt;/br&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/advisor-vectorization-resources.html&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize call(s) to virtual method </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/current/pragmas.html&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/advisor-vectorization-resources.html&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>std::array&lt;struct body,10000&gt;::operator[]</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>38</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>69</unsignedInt:flags>
   <id>issue_check_access_patterns</id>
   <int:severity>2</int:severity>
   <text>Inefficient memory access patterns may result in significant vector code execution slowdown or block automatic vectorization by the compiler. Improve performance by investigating. </text>
   <title>Possible inefficient memory access patterns present </title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_check_access_patterns_run_map_c</id>
     <text>There is no confirmation inefficient memory access patterns are present. To confirm: Run a &lt;a href=&quot;../help/index.htm#GUID-B98AD81B-4946-4E86-B452-9A1810F4517C.htm&quot;&gt;Memory Access Patterns analysis&lt;/a&gt;. </text>
     <title>Confirm inefficient memory access patterns </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:no_map_disclaimer>true</boolean:no_map_disclaimer>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>38</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_fma</id>
   <int:severity>1</int:severity>
   <text>Your current hardware supports the AVX2 instruction set architecture (ISA), which enables the use of fused multiply-add (FMA) instructions. Improve performance by utilizing FMA instructions. </text>
   <title>Potential underutilization of FMA instructions </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_fma_target_avx2_isa_c</id>
     <text>Although static analysis presumes the loop may benefit from FMA instructions available with the AVX2 ISA, no AVX2-specific code executed for this loop. To fix: Use the &lt;div class=&quot;inplace_sample&quot;&gt;xCORE-AVX2&lt;/div&gt; compiler option to generate AVX2-specific code, or the &lt;div class=&quot;inplace_sample&quot;&gt;axCORE-AVX2&lt;/div&gt; compiler option to enable multiple, feature-specific, auto-dispatch code generation, including AVX2. &lt;table&gt; &lt;tr&gt; &lt;th&gt; Windows* OS &lt;/th&gt; &lt;th&gt; Linux* OS &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;/QxCORE-AVX2 or /QaxCORE-AVX2&lt;/td&gt; &lt;td&gt;-xCORE-AVX2 or -axCORE-AVX2&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More: &lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-2D881A91-C5D7-4DDD-84B1-FB9D0D597F4D.htm&quot;&gt;ax, Qax&lt;/a&gt;; &lt;a href=&quot;C++/17/index.htm#GUID-09734487-1819-4C1E-B314-2497F2B64C45.htm&quot;&gt;x, Qx&lt;/a&gt;
&lt;li&gt;&lt;em&gt;Code Generation Options&lt;/em&gt; in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/current/overview.html&quot;&gt;Intel&amp;reg; C++ Compiler 16.0 User and Reference Guide&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/architecture-and-technology/avx-512-solution-brief.html&quot;&gt;Compiling for the Intel&amp;reg; Xeon Phi&amp;trade; processor x200 and the Intel&amp;reg; AVX-512 ISA&lt;/a&gt; and &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/advisor-vectorization-resources.html&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Target the AVX2 ISA </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>38</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_simd_c</id>
     <text>Force vectorization of the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; using SIMD instructions and/or generate vector variants of the function(s) using a &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;br/&gt;&lt;b&gt;Example:&lt;/b&gt; &lt;br/&gt; Original code: &lt;div class=&quot;sample&quot;&gt; struct A {&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;virtual double foo(double x) { return x+1; }&lt;br/&gt; };&lt;br/&gt; &lt;br/&gt; struct B : public A {&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;double foo(double x) override { return x-1; }&lt;br/&gt; };&lt;br/&gt; &lt;br/&gt; . . .&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;A* obj = new B();&lt;br/&gt; &lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;double sum = 0.0;&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;#pragma omp simd reduction(+:sum)&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;for (int k = 0; k &lt; N; ++k) {&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;// indirect call to virtual method&lt;/strong&gt;&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;sum += obj-&gt;foo(a[k]);&lt;/strong&gt;&lt;br/&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;}&lt;br/&gt; . . . &lt;/div&gt; Revised code: &lt;div class=&quot;sample&quot;&gt; struct A {&lt;br/&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;#pragma omp declare simd&lt;br/&gt;&lt;/strong&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;virtual double foo(double x) { return x+1; }&lt;br/&gt; };&lt;br/&gt; . . . &lt;/div&gt;
&lt;/br&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/advisor-vectorization-resources.html&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize call(s) to virtual method </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>38</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>40</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>41</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>69</unsignedInt:flags>
   <id>issue_check_access_patterns</id>
   <int:severity>2</int:severity>
   <text>Inefficient memory access patterns may result in significant vector code execution slowdown or block automatic vectorization by the compiler. Improve performance by investigating. </text>
   <title>Possible inefficient memory access patterns present </title>
   <attributes>
    <float:roofline_impact>1</float:roofline_impact>
    <float:severity>2</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_check_access_patterns_run_map_c</id>
     <text>There is no confirmation inefficient memory access patterns are present. To confirm: Run a &lt;a href=&quot;../help/index.htm#GUID-B98AD81B-4946-4E86-B452-9A1810F4517C.htm&quot;&gt;Memory Access Patterns analysis&lt;/a&gt;. </text>
     <title>Confirm inefficient memory access patterns </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:no_map_disclaimer>true</boolean:no_map_disclaimer>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>48</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>321</unsignedInt:flags>
   <id>issue_roofline_guidance</id>
   <int:severity>2</int:severity>
   <text/>
   <title>issue_roofline_guidance_title</title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters boolean:is_vectorized="true" zone="mem" ops_type="int"/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_roofline_guidance_memory_bound</id>
     <text>roofline_guidance_memory_bound_text</text>
     <title>This loop is mostly memory bound </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:is_vectorized>true</boolean:is_vectorized>
      <boolean:is_fma_dominated>false</boolean:is_fma_dominated>
      <boolean:scalar_mem_instructions>false</boolean:scalar_mem_instructions>
      <current_isa>SSE2</current_isa>
      <best_isa>AVX2</best_isa>
      <traits>Shuffles, Shifts</traits>
      <boolean:inefficient_map>true</boolean:inefficient_map>
      <boolean:low_vector_efficiency>false</boolean:low_vector_efficiency>
      <int:limiting_roof>3</int:limiting_roof>
     </parameters>
    </recommendation>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_roofline_guidance_collect_all_memory_levels</id>
     <text>rec_roofline_guidance_collect_text</text>
     <title>Collect Roofline for all memory levels </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>48</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>321</unsignedInt:flags>
   <id>issue_roofline_guidance</id>
   <int:severity>2</int:severity>
   <text/>
   <title>issue_roofline_guidance_title</title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters boolean:is_vectorized="false" zone="comp" ops_type="int"/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_roofline_guidance_compute_bound</id>
     <text>roofline_guidance_compute_bound_text</text>
     <title>This loop is mostly compute bound </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:is_vectorized>false</boolean:is_vectorized>
      <boolean:is_fma_dominated>false</boolean:is_fma_dominated>
      <boolean:scalar_mem_instructions>false</boolean:scalar_mem_instructions>
      <boolean:inefficient_map>false</boolean:inefficient_map>
      <boolean:low_vector_efficiency>false</boolean:low_vector_efficiency>
      <int:limiting_roof>0</int:limiting_roof>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>51</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>142</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>578</unsignedInt:flags>
   <id>compiler_diag_issue_0</id>
   <int:severity>1</int:severity>
   <text/>
   <title/>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations/>
   <unsignedLong:rowKey>142</unsignedLong:rowKey>
  </issue>
 </issues>
 <traits>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>1</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>4</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>6</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>6</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>9</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>13</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>14</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>24</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>44</int:fieldId>
   <int:id>2</int:id>
   <text>Irregular Memory Access Patterns May Decrease Performance 
Suggestion: See Recommendations Tab </text>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>26</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>29</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>30</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>44</int:fieldId>
   <int:id>2</int:id>
   <text>Irregular Memory Access Patterns May Decrease Performance 
Suggestion: See Recommendations Tab </text>
   <unsignedLong:rowKey>38</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>41</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>42</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>42</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>44</int:fieldId>
   <int:id>2</int:id>
   <text>Irregular Memory Access Patterns May Decrease Performance 
Suggestion: See Recommendations Tab </text>
   <unsignedLong:rowKey>48</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>142</unsignedLong:rowKey>
  </trait>
 </traits>
</bag>
